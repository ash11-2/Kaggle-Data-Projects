{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":40,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntrain_data.shape","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"(7613, 5)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ntest_data.shape","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"(3263, 4)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Data')\nprint(train_data.head(5))\nprint('-----------------------------------------------------------------------------------')\nprint('Test Data')\nprint(test_data.head(5))","execution_count":43,"outputs":[{"output_type":"stream","text":"Training Data\n   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  \n-----------------------------------------------------------------------------------\nTest Data\n   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Text Preprocessing - Pipeline\n* CountVectorizer -Text to token integer counts\n* TF-IDF transformer - integer to TFIDF scores\n* Classifier - train TFIDF  vectors with Logistic Regression\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import  TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_text(text):\n    \"\"\"\n    Removes punctuations(if any), stopwords and returns a list words\n    \"\"\"\n    rm_pun = [char for char in text if char not in string.punctuation]\n    rm_pun = ''.join(rm_pun)\n    \n    return [word for word in rm_pun.split() if word.lower() not in stopwords.words('english')]","execution_count":45,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n    ('cv', CountVectorizer(analyzer=process_text)),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', LogisticRegression()),\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n    ('cv', CountVectorizer(analyzer=process_text)),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', SVC()),\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RandomForest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n    ('cv', CountVectorizer(analyzer=process_text)),  \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', RandomForestClassifier(n_estimators=600)),\n])","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline.fit(train_data['text'],train_data['target'])","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"Pipeline(steps=[('cv',\n                 CountVectorizer(analyzer=<function process_text at 0x7f5557c43710>)),\n                ('tfidf', TfidfTransformer()),\n                ('classifier', RandomForestClassifier(n_estimators=600))])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Test Data Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = pipeline.predict(test_data['text'])","execution_count":49,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# File Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"   id  target\n0   0       1\n1   2       1\n2   3       1\n3   9       0\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv(\"submission.csv\", index=False)","execution_count":51,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}